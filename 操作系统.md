# 操作系统

 ## Kernel特征

1. 并发
   - 时间段

2. 共享

   - 同时共享
   - 互斥共享

3. 虚拟
   - 多道程序

4. 异步

   - 走走停停，速度不可知
   - 环境相同，结果一致

## 启动

### 顺序

BIOS -> boot loader -> OS

### 内核态

#### 系统调用

- 来源：应用程序请求操作提供服务
- 处理时间：异步/同步（取决于应用程序）
- 响应：等待和持续
- 处理步骤：
  1. 用户态程序将数据放入寄存器中, 以此表明需要操作系统提供的服务；
  2. 用户态程序执行陷阱指令；
  3. CPU切换到内核态, 并跳到位于内存指定位置的指令, 这些指令是操作系统的一部分, 他们具有内存保护, 不可被用户态程序访问；
  4. 系统调用完成后, 操作系统会重置CPU为用户态并返回系统调用的结果。

#### 异常

- 来源：应用程序执行中意想不到的行为
- 处理时间：同步
- 响应：杀死程序或重新执行程序
- 处理步骤：
  1. 保存现场
  2. 异常处理
     - 杀死产生异常的程序
     - 重新执行异常指令
  3. 恢复现场

#### 中断

- 来源：外设
- 处理时间：异步
- 响应：持续，对用户应用程序是透明的
- 处理步骤：
  1. 保存当前处理状态
  2. 中断处理
  3. 清楚中断标记
  4. 恢复之前保存的状态

#### 跨越操作系统边界的开销

- 在执行时间上的开销超过程序调用（函数调用）
- 开销：
  1. 建立中断/异常/系统调用号与对应服务例程映射关系的初始化开销
  2. 建立内核堆栈
  3. 验证参数（确保应用操作的安全性）
  4. 内核态映射到用户态的地址空间
     - 更新页面映射的权限
  5. 内核态独立地址空间

## 计算机体系结构及内存分层体系

### 地址空间及地址生成

1. 物理地址空间
   - 硬件支持的地址空间
2. 逻辑地址空间
   - 一个运行的程序所有用的内存范围

地址偏移量+逻辑地址=物理地址（mmu负责维护映射表）

### 连续内存分配

 #### 内存动态分配

1. 首次适配算法
   - 需求：
     1. 按地址排序的空闲块列表
     2. 回收时需要检查是否可以合并成更大的空闲分区
   - 优点：
     1. 简单
     2. 易于产生更大的空闲块
   - 缺点：
     1. 外部碎片
     2. 不确定性
2. 最优适配算法
   - 需求：
     1. 按尺寸排列的空闲块列表，使用所有空闲块中与所需差值最小的空闲块
     2. 回收时需要检查是否可以合并成更大的空闲分区
   - 优势：
     1. 比较简单
     2. 最小化外部碎片产生
     3. 适用于小尺寸
   - 缺点：
     1. 大量外部微小碎片
     2. 回收慢
3. 最差适配算法
   - 需求：与最优适配算法相反
   - 优势：
     1. 避免外部微小碎片
     2. 分配速度快
     3. 适用于中等尺寸
   - 缺点：
     1. 回收慢
     2. 不适用于大块

#### 碎片整理

1. 压缩式碎片整理
   - 重置程序地址以合并碎片
   - 要求所有程序是动态可重置的
   - 议题
     - 何时重置
     - 开销
2. 交换式碎片整理
   - 硬盘作为内存的延伸和硬盘中等待的进程进行换入换出
   - 议题
     - 哪些程序交换

### 非连续内存分配

- 优点：

  1. 程序的物理地址空间是非连续的
  2. 更好的内存利用和管理
  3. 允许共享代码与数据
  4. 支持动态加载和动态链接

- 缺点：

  虚拟地址和物理地址之间转换所带来的开销

#### 分段

 - 分段寻址方案：段号+段内偏移

#### 分页

- 空间划分：划分物理内存至固定大小的帧，虚拟内存同时划分同样大小的页
- 分页寻址方案：页号->帧号，帧号+帧内偏移

- 页表：维护页号到帧号的映射
  - TLB：使用关联内存实现，具有快速访问的性能，用于缓存近期访问的列表项
  - 多级页表：大页表寻址->多个小页表寻址（一级页表不存在的项，二级页表可以不用保留）
  - 反向页表：翻转页表中页号和帧号的位置，使页表大小不正比于逻辑地址大小而正比于物理地址大小
    1. 页寄存器方案
    2. 关联内存方案：造价开销大
    3. 基于哈希查找的方案：哈希碰撞



## 虚拟内存

### 覆盖技术（程序员管理）

- 目标：在较小的内存中运行较大的程序
- 位置：一个大程序内
- 原理：把程序换分为多个相对独立的程序模块
  1. 必要部分常驻
  2. 可选部分平时存在于外存中，需要时才装入内存
  3. 不存在相互调用关系的模块分时共享一块内存
- 缺点：
  1. 确定覆盖关系增加了程序的复杂度
  2. 覆盖过程增加了时间开销

### 交换技术（操作系统管理）

- 目标：让正在运行或需要运行的程序获得更多的内存资源
- 位置：多个程序间
- 方法：
  1. 将暂时不运行的程序送到外存
  2. 操作系统把**一个进程**的的整个地址空间的内容保存到外存（swap out），在需要时再读入内存（swap in）

### 虚拟内存管理技术

- 目标：不把一个程序的所有内容都放到内存中（以细粒度划分——页），且由操作系统自动管理。

- 流程：装入必要页 ==> 发现需要数据未在内存 ==> 

  ​			发出缺页请求 ==> 操作系统将相应页面调入内存 ==> 

  ​			修改页表 ==> 修改驻留位 ==>

  ​			继续执行 ==> 暂时不需要的页面调出到外存

 - 特征：
   1. 大的用户空间：内存+外存
   2. 部分交换
   3. 不连续性
- 页表表项（辅助置换）
  1. 驻留位：该页是否在内存
  2. 保护位：允许对该页做什么操作，只读，可执行等
  3. 修改位：表示该页在内存中是否被修改过。当系统回收物理页时，根据此位来决定是否把内容写回外存
  4. 访问位：该页面是否被访问过

### 页面置换算法

#### 	局部页面置换算法

- **目标**：尽量减少页面的换入换出的次数

- **算法介绍**：
  
1. 最优页面置换算法（不能实现）：
   
   - 思路：计算保存在内存中的每个逻辑页面下次访问还需要等待多长时间，选择最长的作为置换页面
   
2. 先进先出算法（FIFO）：
   
   - 思路：选择内存中驻留时间最长的页面并淘汰
   
   - 特点：特点较差，调出的页面可能是经常要访问的，并且有Belady现象
       - Belady现象：
     - 现象描述：采用FIFO算法时，会出现分配的物理页面数增加，缺页率反而提高的异常现象
         - 原因：算法与内存访问的动态特征矛盾，只体现了存在时长，没体现访问间隔
   
 3. 最近最久未使用（LRU）：

    - 思路：选择最久未使用的页面并淘汰

    - 优点：适用于代码局部性好的情况
        - 缺点：需要记录页面使用的先后顺序，开销大

 4. 时钟页面置换算法（Clock）⭐：

    - 思路：将页面组织成环形链表，使用指针循环扫描其中访问位，若为1置0，若为0置换

    - 优化：二次机会

      | used_before | dirty_before |      | used_after | dirty_after |
      | :---------: | :----------: | ---- | :--------: | :---------: |
    |      0      |      0       | ==>  |  replace   |   replace   |
      |      0      |      1       | ==>  |     0      |      0      |
    |      1      |      0       | ==>  |     0      |      0      |
      |      1      |      1       | ==>  |     0      |      1      |

5. 最不常用算法：

   - 思路：选择访问次数最少的页并淘汰
   - 缺点：只考虑了次数没考虑时间 ==> 初始化文件很长时间之内不会被淘汰
#### 全局页面置换算法

- 目标：尽可能优化整个内存空间，使多个进程可以共享内存

- 算法介绍：

    1. 工作集页面置换算法：
       - 思路：换出超出工作窗口（固定窗口）的页面
    2. 缺页率页面置换算法：
       - 思路：缺页率高时，增加工作集；缺页率低时，减少工作集

- 抖动问题：常驻集和工作集不匹配，导致频繁的内外存换入换出

## 进程管理

### 进程的定义

#### 进程的组成

- 进程的代码
- 进程处理的数据
- 程序计数器
- 堆、栈
- 系统资源

#### 进程的特点

- 动态性：动态创建和结束进程
- 并发性
- 独立性
- 制约性：进程间同步

#### 进程的状态

- 生命周期：
  1. 创建
     - 系统初始化
     - 用户请求创建
     - 正在运行的进程执行了创建进程的系统调用
  2. 就绪
  3. 运行
     - 内核选择一个就绪的进程，让它占用cpu时间片
  4. 等待（阻塞）
     - 请求并等待系统服务，无法马上完成
     - 启动某种操作（进程协同），无法马上完成
     - 需要数据没有到达
  5. 结束
     - 正常退出（自愿）
     - 错误推出（自愿）
     - 致命错误（强制）
     - 被其他进程杀死（强制）
- 进程挂起：进程没有占用内存空间
  1. 阻塞挂起：进程在外存并等待某事件的出现
     - 阻塞到阻塞挂起
  2. 就绪挂起：进程在外存，只要进入内存即可运行
     - 就绪到就绪挂起
     - 运行到就绪挂起
- 进程激活：
  1. 就绪挂起到就绪
  2. 阻塞挂起到阻塞

### 线程的定义

#### 优缺点

- 优点：
  1. 一个进程中可以存在多个线程
  2. 各线程间可以并发执行
  3. 各线程间可以共享资源

- 缺点：
  1. 不独立，一个线程崩溃，所有线程崩溃

#### 线程的实现

- 内核线程
  - 概念：线程调度由操作系统来完成
  - 缺点：频繁的内核态/用户态切换
- 用户线程
  - 概念：线程调度由用户级的线程库函数来完成
  - 缺点：线程运行后除非主动交出CPU使用权，其他线程无法执行
- 轻量级进程
  - 概念：内核支持用户线程，进程可以有多个轻量级进程，每个量级进程由一个单独的内核线程来支持

### 进程和线程的比较

- 进程是资源分配单位，线程是CPU任务调度单位
- 进程拥有完成的资源平台，线程只独享必不可少的资源
- 线程能减少并发执行的时间和空间开销
  1. 线程的创建和终止时间短
  2. 同一进程内线程切换时间短（页表切换）
  3. 多个线程资源共享，不需要通信

| 维度           | 多进程                              | 多线程                            |
| -------------- | ----------------------------------- | --------------------------------- |
| 数据共享、同步 | 各进程独立，共享复杂，同步简单      | 各线程共享进程资源，但同步复杂    |
| 硬件资源利用率 | 内存占用大，切换开销大，CPU利用率低 | 内存占用小，切换简单，CPU利用率高 |
| 编程难度       | 低                                  | 高                                |
| 可靠性         | 各进程独立，不互相影响              | 一个线程挂，所属进程的所有线程挂  |
| 分布式         | 适用于多机分布式                    | 适用于多核分布式                  |

### 上下文切换

- 概念：停止当前运行的**进程**并且调度其他进程
- 上下文：寄存器，cpu状态（PCB）
- 控制队列：就绪队列、等待I/O队列、僵尸队列

### 进程中某个线程崩溃的后果

- 如果进程不屏蔽segment fault信号，一个线程崩溃则真个进程挂；
- 若屏蔽segment fault信号，若崩溃为止在私有位置（栈），则进程没问题；
- 若屏蔽segment fault信号，若崩溃为止在共享位置（堆，常量池），则进程也会出现问题；



## 任务调度

### 评价指标

1. CPU使用率
2. 吞吐量：单位时间内完成的进程数
3. 周转时间：一个进程从初始化到结束花费的时间
4. 等待时间：进程在就绪队列中的总时间
5. 响应时间：从请求被提交到产生第一次响应花费的时间

### 调度算法

1. **先来先服务**（FCFS）
- 概念：先来先服务，如果进程在执行中阻塞，队列中的下一个进程才会得到CPU
   - 缺点：由于长任务导致响应时间慢
   
2. **短任务优先**（SPN，SRT）
- 概念：非抢占（抢占）式的选择下一个最短的进程
   - 优点：最短平均等待时间
   - 缺点：
     1. 长任务饿死
     2. 需要预先知道进程的运行时间
   
3. **最高响应优先**（HRRN）：
- 概念：等待时间+执行时间 / 执行时间 （不可抢占）
  
- 优点：防止饿死
  
- 缺点：需要预先知道进程的运行时间

4. **轮询算法**（RR）：
   - 概念：每个进程轮流占用一个CPU时间片
   - 优点：公平
   - 缺点：
     1. 额外的上下文切换开销
     2. 时间片大小不好确定
     3. 平均等待时间大

5. **多级反馈队列**（MLFQ）：
   - 多个队列采用自己的调度方式，并且可以在队列中穿梭
6. **公平共享调度算法**（FSS）：
   - 用户级别的公平共享CPU方法

### 实时调度

- 定义：保证任务的实时性（在规定时间内完成）

1. 速率单调调度（RM）：
   - 最佳静态优先调度
   - 通过周期安排优先级
   - 周期越短优先级越高
   - 执行周期最短的任务
2. 最早期限调度（EDF）：
   - 最佳动态优先级调度
   - Deadline越早优先级越高
   - 执行Deadline最早的任务



## 进程同步

### 临界区（互斥）

- 临界区：多个进程可共享资源的那段代码（static）
- 互斥：当一个进程处于临界区访问资源时，没有其他进程进入该临界区
- 死锁：两个或两个以上的进程，互相等待对方持有的资源
- 饥饿：一个可执行的进程，被调度器持续忽略

### 信号量（互斥，多进程同步）

- 信号量：当信号量达到一定水平才执行操作
- 分类：互斥信号量，同步信号量
- 缺点：
  1. 代码编写困难
  2. 容易出错
  3. 不能处理死锁

### 管程（分离互斥和同步）

- 管程：一个锁（互斥）和多个条件变量（线程挂起空间）

### ~~会合（用于分布式系统）~~



## 死锁

- 定义：两个或两个以上的进程，互相等待对方持有的资源

- 特征（必要条件）：
  1. 互斥：在一个时间内只能有一个进程使用资源
  2. 持有并等待：进程持有一个以上的资源并等待获取其他进程持有的资源
  3. 不抢占：一个资源只能被进程资源释放
  4. 循环等待：进程资源图中形成环
- 解决死锁的方法：
  - 预防：打破四个必要条件之一
    1. 持有并等待：一次性分配（批处理）；
    2. 不抢占：等待一定时间放弃资源；
    3. 循环等待：按顺序分配。
  - 避免：银行家算法
  - 检测：O(m*n^2^)算法，很少用
  - 恢复：
    1. kill占用资源的进程（考虑优先级）
    2. 回滚：返回到安全状态



## 进程通信

### 信号

- 定义：软件中断通知时间处理
- 响应：Catch（指定信号处理函数）、Ignore（交给操作系统）、Mask
- 优势：快捷，异步
- 不足：不能传输数据

### 管道

- 定义：***由父进程创建***，将一个子进程的输出作为其他子进程的输入串联起来
- 优势：可以传输数据
- 不足：
  1. 只能由父进程创建
  2. 数据没有结构

### 消息队列

- 定义：按FIFO的方式来管理**消息**
- 优势：
  1. 兄弟进程也可以通信
  2. 数据可以有结构

### 共享内存

- 定义：在创建时，明确出一块共享内存段
- 优点：直接通信，最快
- 不足：需要同步

### 套接字

- 定义：通过唯一编号，确定网络中的进程
- 优点：支持进程通过网络通信



## IO

### 同步阻塞IO

<img src="C:\Users\Carrot97\Desktop\笔记\git\pic\20180619142343598.png" alt="20180619142343598" style="zoom: 33%;" />

- 原理：用户线程通过系统调用read发起IO读操作，由用户空间转到内核空间。内核等到数据包到达后，然后将接收的数据拷贝到用户空间，完成read操作；
- 不足：IO请求时，不能做任何事情，对CPU的资源利用率不够。

### 同步非阻塞IO

<img src="C:\Users\Carrot97\Desktop\笔记\git\pic\20180619142817523.png" alt="20180619142817523" style="zoom:33%;" />

```c
while(read(socket, buffer) != SUCCESS);
process(buffer);
```



- 原理：因此用户线程发起IO请求时立即返回。但并未读取到任何数据，用户线程需要不断地发起IO请求，直到数据到达后，才真正读取到数据，继续执行；
- 优势：解决阻塞问题；
- 不足：用户线程每次发起IO请求后可以立即返回，但是为了等到数据，仍需要不断地轮询、重复请求，消耗了大量的CPU的资源。

### 多路复用IO

<img src="C:\Users\Carrot97\Desktop\笔记\git\pic\20180619143047791.png" alt="20180619143047791" style="zoom:33%;" />

```c
select(socket);
while(1) {
    sockets = select();
    for(socket in sockets) {
        if(can_read(socket)) {
            read(socket, buffer);
            process(buffer);
        }
    }
}
```

- 原理：IO多路复用模型是建立在内核提供的多路分离函数select基础之上的，使用select函数可以避免同步非阻塞IO模型中轮询等待的问题。其中while循环前将socket添加到select监视中，然后在while内一直调用select获取被激活的socket，一旦socket可读，便调用read函数将socket中的数据读取出来。

- 优势：在同一个线程内同时处理多个IO请求；

- 不足：每个IO请求的过程还是阻塞的（在select函数上阻塞），平均时间甚至比同步阻塞IO模型还要长。

- details：

  1. select

     特点：

     - 会修改传入的参数数组；
     - select返回时不会通知那个sock有数据，每次都需要轮询；
     - 只能监视1024个链接；
     - 线程不安全。

  2. poll

     改进：

     - 移除监视1024个链接的限制；
     - 不修改传入的参数数组。

  3. epoll

     改进：

     - 线程安全；
     - 可以通知那个sock组里有数据。
     - 使用共享内存，免去数据拷贝
  
- 适用场景：

  1. 处理多个描述字；
  2. 处理多个套接口；
  3. tcp服务器即监听套接口，又处理已连接的套接口；
  4. 即处理tcp又处理udp；
  5. 一个服务器处理多个服务和协议

### 异步IO

<img src="C:\Users\Carrot97\Desktop\笔记\git\pic\20180619143401398.png" alt="20180619143401398" style="zoom:33%;" />



- 原理：用户线程直接使用内核提供的异步IO API发起read请求，且发起后立即返回，继续执行用户线程代码。不过此时用户线程已经将调用的自身信息注册到内核，然后操作系统开启独立的内核线程去处理IO操作。当read请求的数据到达时，由内核负责读取socket中的数据，并写入用户指定的缓冲区中。最后内核将read的数据和用户线程注册的用户线程信息分发给内部Proactor，Proactor将IO完成的信息通知给用户线程；
- 优势：真正意义上的异步；
- 不足：使用难度高，还不完善。





​	



































































